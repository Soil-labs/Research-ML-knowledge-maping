{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soil-labs/Research-ML-knowledge-maping/blob/main/v4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://openai.com/blog/introducing-text-and-code-embeddings/"
      ],
      "metadata": {
        "id": "_py2vtHRyLk3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JvAXGZk9ZPNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "59ce4a98-8cdb-400b-e9a7-28dbec08f279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.8/dist-packages (0.25.0)\n",
            "Requirement already satisfied: pandas-stubs>=1.1.0.11 in /usr/local/lib/python3.8/dist-packages (from openai) (1.5.2.221213)\n",
            "Requirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: types-pytz>=2022.1.1 in /usr/local/lib/python3.8/dist-packages (from pandas-stubs>=1.1.0.11->openai) (2022.7.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **embedding is an information dense representation of the semantic meaning of a piece of text**. <br>\n",
        "Each embedding is a vector of floating point numbers, such that the **distance between two embeddings in the vector space is correlated with semantic similarity between two inputs** in the original format. <br>\n",
        "For example, if two texts are similar, then their vector representations should also be similar."
      ],
      "metadata": {
        "id": "EYls8nVLZg22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use cases:**\n",
        "\n",
        "*   Text Similarity\n",
        "*   Semantic Search\n",
        "*   Classification\n",
        "*   Clustering\n"
      ],
      "metadata": {
        "id": "_vsj-XmcZnWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   **Similarity embeddings** : These models are good at capturing semantic similarity between two or more pieces of text.\n",
        "2.   **Text search embeddings**: These models help measure whether long documents are relevant to a short search query. There are two types: one for ***embedding the documents*** to be retrieved, and one for ***embedding the search query***.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-ZfNmsxwZyuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai, numpy as np\n",
        "from openai.embeddings_utils import get_embedding, cosine_similarity"
      ],
      "metadata": {
        "id": "XTLL1cu1UV-l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = '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'\n",
        "openai.api_key = api_key\n"
      ],
      "metadata": {
        "id": "0PHGwPjPT6wa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_search = \"I start coding today, I love working on javascript but I want to be more structure with neo4j and now I will start working with convolutional neural networks togehter with Figma\" # design\n",
        "# text_search = \"Yesterday I start working for the first time with Figma and Canva, it is great adition to my skills, can't wait to spent more time with tools except photoshop\" # front\n",
        "# text_search = \"Finally I start working with a user research, we are trying to uderstand better the users, \" #product\n",
        "# text_search = \"my dad left me at the age of 3 and now I have a separation anxiety\" #nothing\n",
        "# text_search = \"I went ot the art school for 9 years\" #design\n",
        "# text_search = \"I am a retire marine corps, and I have served on the front\" #nothing\n",
        "# text_search = \"I start building a website, at age 8 now I am in google\" # design # FrontEnd\n",
        "# text_search = \"I start photography but now I want to focus on buidling for companies\" # design \n",
        "text_search = \"I finally learned how to work with node.js but also I want to focus more on react and angular\" # FrontEnd\n",
        "# text_search = \"I start learning hw to design websites, I use photoshop and I start drawingm circles\" #design\n",
        "# text_search = \"there was so much snow that the flight didn't land but after all we met with my family and it was fun\" #nothing\n",
        "\n",
        "\n",
        "\n",
        "question_ask = \"Extract keywords from this text:\\n\\n\" + text_search + \"\\n\\n Result:\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=question_ask,\n",
        "  temperature=0.5,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.8,\n",
        "  presence_penalty=0\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "_zgVKbSM6fFR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "jwdJBYtw7Wmx",
        "outputId": "cbfa9d95-3ce7-4467-c9b5-71c102c174b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "node.js, react, angular\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Text Similarity</h3>"
      ],
      "metadata": {
        "id": "-qkKIhw-UqJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# words_n = [\"Neo4j\",\"react\",\"next.js\",\"Figma\",\"design\",\"visual\",\"graphic\",\"art\", \"Javascript\", \"Coding\" ,\"CNN\", \"react\",\"water\",\"object\",\"Convolutional Neural Networks\",\"Machine Learning\",\"cherry\",\"pie\"]\n",
        "words_n = response[\"choices\"][0][\"text\"].split(', ')\n",
        "resp = openai.Embedding.create(\n",
        "    input=words_n,\n",
        "    engine=\"text-similarity-davinci-001\")\n",
        "\n",
        "\n",
        "# words_n_base = [\"UI Design\"]\n",
        "words_n_base = [\"Design\",\"UX/UI\",\"Graphic Design\",\"Web Design\",\"Game Design\",\"Animation\",\"General Design support from A-Z\",\"NFT Design\",\"Brand Design\"]\n",
        "resp_base = openai.Embedding.create(\n",
        "    input=words_n_base,\n",
        "    engine=\"text-similarity-davinci-001\")\n",
        "\n",
        "\n",
        "words_n_base_front = [\"Frontend Developer\",\"UI Implementation\",\"Frontend Architecture\",\"General Frontend Support\",\"Web Development\",\"App Development\"]\n",
        "resp_base_front = openai.Embedding.create(\n",
        "    input=words_n_base_front,\n",
        "    engine=\"text-similarity-davinci-001\")\n",
        "\n",
        "\n",
        "words_n_base_product = [\"Product Manager\",\"User Research\",\"Market Research\",\"Technical Team Coordination\",\"Design Team Coordination\",\"Ideation\",\"Interviews\"]\n",
        "resp_base_product = openai.Embedding.create(\n",
        "    input=words_n_base_product,\n",
        "    engine=\"text-similarity-davinci-001\")"
      ],
      "metadata": {
        "id": "uJQ1P7fsTyX4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_embed = []\n",
        "for i in range(len( resp['data'])):\n",
        "  words_embed.append(resp['data'][i]['embedding'])\n",
        "\n",
        "\n",
        "words_embed_base = []\n",
        "for i in range(len( resp_base['data'])):\n",
        "  words_embed_base.append(resp_base['data'][i]['embedding'])\n",
        "\n",
        "\n",
        "words_embed_base_front = []\n",
        "for i in range(len( resp_base_front['data'])):\n",
        "  words_embed_base_front.append(resp_base_front['data'][i]['embedding'])\n",
        "\n",
        "\n",
        "words_embed_base_product = []\n",
        "for i in range(len( resp_base_product['data'])):\n",
        "  words_embed_base_product.append(resp_base_product['data'][i]['embedding'])\n",
        "\n",
        "\n",
        "words_base_all = []\n",
        "words_base_all.append(words_embed_base)\n",
        "words_base_all.append(words_embed_base_front)\n",
        "words_base_all.append(words_embed_base_product)\n",
        "\n",
        "# print(words_base_all[1])\n",
        "# print(words_embed_base_front)"
      ],
      "metadata": {
        "id": "I5S-imSkUGyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 10 # k best embeddings\n",
        "emb_mat = np.stack(words_embed)\n",
        "# print(emb_mat)\n",
        "\n",
        "emb_mat_base_all = []\n",
        "for i in range(len(words_base_all)):\n",
        "  emb_mat_base = np.stack(words_base_all[i])\n",
        "  \n",
        "  emb_mat_base_all.append(emb_mat_base)\n",
        "\n",
        "\n",
        "emb_mat_base = np.stack(words_embed_base)\n",
        "# print(emb_mat_base)\n",
        "\n",
        "\n",
        "emb_mat_base_front = np.stack(words_embed_base_front)\n",
        "# print(emb_mat_base_front)\n",
        "\n",
        "emb_mat_base_product = np.stack(words_embed_base_product)\n",
        "# print(emb_mat_base_product)\n"
      ],
      "metadata": {
        "id": "f9YefpiYND3n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chooseWord = 3\n",
        "scores = np.dot(emb_mat_base,emb_mat.T)\n",
        "# scores = np.dot(emb_mat,emb_mat_base.T)\n",
        "print(scores)\n",
        "\n",
        "\n",
        "scores_base_all = []\n",
        "for i in range(len(words_base_all)):\n",
        "  scores_base = np.dot(emb_mat_base_all[i],emb_mat.T)\n",
        "  \n",
        "  scores_base_all.append(scores_base)\n",
        "\n",
        "\n",
        "scores_front = np.dot(emb_mat_base_front,emb_mat.T)\n",
        "\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(scores_front)\n",
        "\n",
        "\n",
        "scores_product = np.dot(emb_mat_base_product,emb_mat.T)\n",
        "\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(scores_product)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV172DOxNPUC",
        "outputId": "838bdcac-88f0-41b6-87c3-c4cb8a8dbb1a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.76279171 0.83401948 0.83865283]\n",
            " [0.78022329 0.81030721 0.80519608]\n",
            " [0.75440394 0.76638343 0.77179573]\n",
            " [0.79910941 0.78289732 0.78273399]\n",
            " [0.77845498 0.79281564 0.79392095]\n",
            " [0.77922495 0.83974771 0.83223032]\n",
            " [0.71362989 0.70414817 0.69448642]\n",
            " [0.77522274 0.78325974 0.78199894]\n",
            " [0.76497504 0.81312547 0.80776582]]\n",
            "\n",
            "\n",
            "[[0.80853791 0.76054106 0.76337418]\n",
            " [0.80490882 0.82467176 0.81233741]\n",
            " [0.81012065 0.77669975 0.78343402]\n",
            " [0.77609293 0.7612373  0.75532717]\n",
            " [0.83281243 0.77754544 0.77522225]\n",
            " [0.81659532 0.79188512 0.79017915]]\n",
            "\n",
            "\n",
            "[[0.77001377 0.76313447 0.75750518]\n",
            " [0.7817497  0.79008274 0.77041588]\n",
            " [0.76082761 0.77158018 0.7608833 ]\n",
            " [0.76866889 0.75028094 0.74556521]\n",
            " [0.75235787 0.75817844 0.74889661]\n",
            " [0.76545487 0.81976373 0.80888975]\n",
            " [0.77467232 0.78254959 0.78292756]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxima = list(map(max, scores))\n",
        "print(maxima)  # Output: [3, 6, 9]\n",
        "\n",
        "maxima_base_all = []\n",
        "for i in range(len(words_base_all)):\n",
        "  maxima_base = list(map(max, scores_base_all[i]))\n",
        "  \n",
        "  maxima_base_all.append(maxima_base)\n",
        "\n",
        "\n",
        "maxima_front = list(map(max, scores_front))\n",
        "print(maxima_front)  # Output: [3, 6, 9]\n",
        "\n",
        "maxima_product = list(map(max, scores_product))\n",
        "print(maxima_product)  # Output: [3, 6, 9]\n",
        "\n",
        "\n",
        "print(maxima_base_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvzUMQ7NVnd7",
        "outputId": "0ff0ac86-08bd-464a-cedc-6fa3d578976a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8386528297724409, 0.8103072146402821, 0.7717957340136551, 0.799109405254009, 0.7939209541344174, 0.8397477060506124, 0.7136298907372705, 0.7832597356811399, 0.8131254703378511]\n",
            "[0.8085379106371029, 0.8246717628717523, 0.8101206461421753, 0.7760929312606785, 0.832812434831967, 0.8165953158013728]\n",
            "[0.770013765039608, 0.790082735335573, 0.7715801835470645, 0.7686688925536842, 0.758178437281094, 0.8197637320833042, 0.7829275611542176]\n",
            "[[0.8386528297724409, 0.8103072146402821, 0.7717957340136551, 0.799109405254009, 0.7939209541344174, 0.8397477060506124, 0.7136298907372705, 0.7832597356811399, 0.8131254703378511], [0.8085379106371029, 0.8246717628717523, 0.8101206461421753, 0.7760929312606785, 0.832812434831967, 0.8165953158013728], [0.770013765039608, 0.790082735335573, 0.7715801835470645, 0.7686688925536842, 0.758178437281094, 0.8197637320833042, 0.7829275611542176]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_n = sum(maxima) / len(maxima)\n",
        "print(\"average Design:\",average_n)\n",
        "\n",
        "\n",
        "average_base_all = []\n",
        "for i in range(len(words_base_all)):\n",
        "  average_base = sum(maxima_base_all[i]) / len(maxima_base_all[i])\n",
        "  \n",
        "  average_base_all.append(average_base)\n",
        "\n",
        "\n",
        "average_n_front = sum(maxima_front) / len(maxima_front)\n",
        "print(\"average FrontEnd:\",average_n_front)\n",
        "\n",
        "average_n_product = sum(maxima_product) / len(maxima_product)\n",
        "print(\"average Product:\",average_n_product)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(average_base_all)"
      ],
      "metadata": {
        "id": "FVZQQdDYnC7R",
        "outputId": "3803f3c5-ea0b-4d4f-ea87-15248c8f185e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average Design: 0.7959498822912976\n",
            "average FrontEnd: 0.8114718335908416\n",
            "average Product: 0.7801736152849349\n",
            "[0.7959498822912976, 0.8114718335908416, 0.7801736152849349]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if (average_n>average_n_front and average_n>average_n_product):\n",
        "  # Do nothing\n",
        "  a = 1\n",
        "\n",
        "if (average_n_front>average_n and average_n_front>average_n_product):\n",
        "  scores = scores_front\n",
        "  words_n_base = words_n_base_front\n",
        "\n",
        "if (average_n_product>average_n and average_n_product>average_n_front):\n",
        "  scores = scores_product\n",
        "  words_n_base = words_n_base_product"
      ],
      "metadata": {
        "id": "GjSSB4PespX2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_pos = scores.argmax(axis=1)\n",
        "\n",
        "print(max_pos)\n",
        "\n",
        "words_np = np.array(words_n)\n",
        "print(max_pos)  \n",
        "print(scores)\n",
        "print(\"\")\n",
        "numberClose = 2\n",
        "threshold = 0.6\n",
        "for i in range(len(max_pos)):\n",
        "  max_elements_position = np.argpartition(scores[i], -numberClose)[-numberClose:]\n",
        "  print(max_elements_position)\n",
        "  # print(\"Correlation = \",scores[i][max_elements_position])\n",
        "\n",
        "  # scores_max_bigger_threshold = [number for number in scores[i][max_elements_position] if number > threshold]\n",
        "\n",
        "  # scores_max_bigger_threshold = []\n",
        "  # for number in scores[i][max_elements_position]:\n",
        "  #   if number > threshold:\n",
        "  #     scores_max_bigger_threshold.append(number)\n",
        "\n",
        "  scores_max_bigger_threshold = []\n",
        "  position_bigger_threshold = []\n",
        "  for pos in max_elements_position:\n",
        "    number = scores[i][pos]\n",
        "    if number > threshold:\n",
        "      scores_max_bigger_threshold.append(number)\n",
        "      position_bigger_threshold.append(pos)\n",
        "\n",
        "  # print(\"Correlation = \" , scores_max_bigger_threshold)\n",
        "\n",
        "\n",
        "  print(\"Base Knowledge Graph Name = \",words_n_base[i])\n",
        "  print(\"Best word to connect = \",words_np[position_bigger_threshold])\n",
        "  print(\"Correlation = \",scores[i][position_bigger_threshold])\n",
        "\n",
        "  # print(\"Base Knowledge Graph Name = \",words_n_base[i])\n",
        "  # print(\"Best word to connect = \",words_np[max_elements_position])\n",
        "  # print(\"Correlation = \",scores[i][max_elements_position])\n",
        "\n",
        "\n",
        "  # print(\"Base Knowledge Graph Name = \",words_n_base[i])\n",
        "  # print(\"Best word to connect = \",words_n[max_pos[i]])\n",
        "  # print(\"Correlation = \",scores[i][max_pos[i]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB0y0EFOV_m8",
        "outputId": "7ff65aba-f791-452e-b428-29833eedcaea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 0 0]\n",
            "[0 1 0 0 0 0]\n",
            "[[0.80853791 0.76054106 0.76337418]\n",
            " [0.80490882 0.82467176 0.81233741]\n",
            " [0.81012065 0.77669975 0.78343402]\n",
            " [0.77609293 0.7612373  0.75532717]\n",
            " [0.83281243 0.77754544 0.77522225]\n",
            " [0.81659532 0.79188512 0.79017915]]\n",
            "\n",
            "[2 0]\n",
            "Base Knowledge Graph Name =  Frontend Developer\n",
            "Best word to connect =  ['angular' '\\nnode.js']\n",
            "Correlation =  [0.76337418 0.80853791]\n",
            "[2 1]\n",
            "Base Knowledge Graph Name =  UI Implementation\n",
            "Best word to connect =  ['angular' 'react']\n",
            "Correlation =  [0.81233741 0.82467176]\n",
            "[2 0]\n",
            "Base Knowledge Graph Name =  Frontend Architecture\n",
            "Best word to connect =  ['angular' '\\nnode.js']\n",
            "Correlation =  [0.78343402 0.81012065]\n",
            "[1 0]\n",
            "Base Knowledge Graph Name =  General Frontend Support\n",
            "Best word to connect =  ['react' '\\nnode.js']\n",
            "Correlation =  [0.7612373  0.77609293]\n",
            "[1 0]\n",
            "Base Knowledge Graph Name =  Web Development\n",
            "Best word to connect =  ['react' '\\nnode.js']\n",
            "Correlation =  [0.77754544 0.83281243]\n",
            "[1 0]\n",
            "Base Knowledge Graph Name =  App Development\n",
            "Best word to connect =  ['react' '\\nnode.js']\n",
            "Correlation =  [0.79188512 0.81659532]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prbest_k_ind = np.argpartition(scores, k) \n",
        "# best_k_ind = np.argpartition(scores, k)[-k:] \n",
        "print(best_k_ind)\n",
        "top_k_emb = emb_mat[best_k_ind] \n",
        "# print(top_k_emb)\n",
        "\n",
        "best_k_words = []\n",
        "for i in range(len(best_k_ind)):\n",
        "  best_k_words.append(words_n[best_k_ind[i]])\n",
        "\n",
        "print(words_n[chooseWord])\n",
        "print()\n",
        "print(best_k_words)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "RvHW6wusNdJK",
        "outputId": "be0773e6-84d0-4e24-84a7-3914821a84a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-87-f178cf8d8cd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprbest_k_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margpartition\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m# best_k_ind = np.argpartition(scores, k)[-k:]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbest_k_ind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtop_k_emb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0memb_mat\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_k_ind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# print(top_k_emb)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36margpartition\u001b[0;34m(a, kth, axis, kind, order)\u001b[0m\n\u001b[1;32m    837\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    838\u001b[0m     \"\"\"\n\u001b[0;32m--> 839\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'argpartition'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    840\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0;31m# A TypeError occurs if the object does have such a method in its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: kth(=10) out of bounds (5)"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Clustering</h3>"
      ],
      "metadata": {
        "id": "jI9wUPHSVzHn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ntc2x0i2xydm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}