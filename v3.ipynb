{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Soil-labs/Research-ML-knowledge-maping/blob/main/v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://openai.com/blog/introducing-text-and-code-embeddings/"
      ],
      "metadata": {
        "id": "_py2vtHRyLk3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JvAXGZk9ZPNY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5dc771a5-e7c1-42c9-a7a5-4b92320aeae8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openai\n",
            "  Downloading openai-0.25.0.tar.gz (44 kB)\n",
            "\u001b[K     |████████████████████████████████| 44 kB 2.6 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas>=1.2.3 in /usr/local/lib/python3.8/dist-packages (from openai) (1.3.5)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.8/dist-packages (from openai) (2.23.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from openai) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from openai) (1.21.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from openai) (4.64.1)\n",
            "Collecting pandas-stubs>=1.1.0.11\n",
            "  Downloading pandas_stubs-1.5.2.221213-py3-none-any.whl (147 kB)\n",
            "\u001b[K     |████████████████████████████████| 147 kB 16.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: openpyxl>=3.0.7 in /usr/local/lib/python3.8/dist-packages (from openai) (3.0.10)\n",
            "Requirement already satisfied: et-xmlfile in /usr/local/lib/python3.8/dist-packages (from openpyxl>=3.0.7->openai) (1.1.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.8/dist-packages (from pandas>=1.2.3->openai) (2022.6)\n",
            "Collecting types-pytz>=2022.1.1\n",
            "  Downloading types_pytz-2022.7.0.0-py3-none-any.whl (4.7 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.3->openai) (1.15.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests>=2.20->openai) (3.0.4)\n",
            "Building wheels for collected packages: openai\n",
            "  Building wheel for openai (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai: filename=openai-0.25.0-py3-none-any.whl size=55880 sha256=a03748cf8cca6dc4db7de143c537b89dff6cb95a4b68a1d049fea7a6a58043cd\n",
            "  Stored in directory: /root/.cache/pip/wheels/4b/92/33/6f57c7aae0b16875267999a50570e81f15eecec577ebe05a2e\n",
            "Successfully built openai\n",
            "Installing collected packages: types-pytz, pandas-stubs, openai\n",
            "Successfully installed openai-0.25.0 pandas-stubs-1.5.2.221213 types-pytz-2022.7.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **embedding is an information dense representation of the semantic meaning of a piece of text**. <br>\n",
        "Each embedding is a vector of floating point numbers, such that the **distance between two embeddings in the vector space is correlated with semantic similarity between two inputs** in the original format. <br>\n",
        "For example, if two texts are similar, then their vector representations should also be similar."
      ],
      "metadata": {
        "id": "EYls8nVLZg22"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Use cases:**\n",
        "\n",
        "*   Text Similarity\n",
        "*   Semantic Search\n",
        "*   Classification\n",
        "*   Clustering\n"
      ],
      "metadata": {
        "id": "_vsj-XmcZnWK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1.   **Similarity embeddings** : These models are good at capturing semantic similarity between two or more pieces of text.\n",
        "2.   **Text search embeddings**: These models help measure whether long documents are relevant to a short search query. There are two types: one for ***embedding the documents*** to be retrieved, and one for ***embedding the search query***.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-ZfNmsxwZyuX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import openai, numpy as np\n",
        "from openai.embeddings_utils import get_embedding, cosine_similarity"
      ],
      "metadata": {
        "id": "XTLL1cu1UV-l"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = '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'\n",
        "openai.api_key = api_key\n"
      ],
      "metadata": {
        "id": "0PHGwPjPT6wa"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# text_search = \"I start coding today, I love working on javascript but I want to be more structure with neo4j and now I will start working with convolutional neural networks togehter with Figma\" # design\n",
        "# text_search = \"Yesterday I start working for the first time with Figma and Canva, it is great adition to my skills, can't wait to spent more time with tools except photoshop\" # front\n",
        "# text_search = \"Finally I start working with a user research, we are trying to uderstand better the users, \" #product\n",
        "# text_search = \"my dad left me at the age of 3 and now I have a separation anxiety\" #nothing\n",
        "# text_search = \"I went ot the art school for 9 years\" #design\n",
        "# text_search = \"I am a retire marine corps, and I have served on the front\" #nothing\n",
        "# text_search = \"I start building a website, at age 8 now I am in google\" # design # FrontEnd\n",
        "# text_search = \"I start photography but now I want to focus on buidling for companies\" # design \n",
        "text_search = \"I finally learned how to work with node.js but also I want to focus more on react and angular\" # FrontEnd\n",
        "# text_search = \"I start learning hw to design websites, I use photoshop and I start drawingm circles\" #design\n",
        "# text_search = \"there was so much snow that the flight didn't land but after all we met with my family and it was fun\" #nothing\n",
        "\n",
        "\n",
        "\n",
        "question_ask = \"Extract keywords from this text:\\n\\n\" + text_search + \"\\n\\n Result:\"\n",
        "\n",
        "response = openai.Completion.create(\n",
        "  model=\"text-davinci-003\",\n",
        "  prompt=question_ask,\n",
        "  temperature=0.5,\n",
        "  max_tokens=60,\n",
        "  top_p=1,\n",
        "  frequency_penalty=0.8,\n",
        "  presence_penalty=0\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "_zgVKbSM6fFR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(response[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "jwdJBYtw7Wmx",
        "outputId": "0a5c9b28-c589-46be-964b-c88420adf3bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "node.js, react, angular\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Text Similarity</h3>"
      ],
      "metadata": {
        "id": "-qkKIhw-UqJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# words_n = [\"Neo4j\",\"react\",\"next.js\",\"Figma\",\"design\",\"visual\",\"graphic\",\"art\", \"Javascript\", \"Coding\" ,\"CNN\", \"react\",\"water\",\"object\",\"Convolutional Neural Networks\",\"Machine Learning\",\"cherry\",\"pie\"]\n",
        "words_n = response[\"choices\"][0][\"text\"].split(', ')\n",
        "resp = openai.Embedding.create(\n",
        "    input=words_n,\n",
        "    engine=\"text-similarity-davinci-001\")\n",
        "\n",
        "\n",
        "# words_n_base = [\"UI Design\"]\n",
        "words_n_base = [\"Design\",\"UX/UI\",\"Graphic Design\",\"Web Design\",\"Game Design\",\"Animation\",\"General Design support from A-Z\",\"NFT Design\",\"Brand Design\"]\n",
        "resp_base = openai.Embedding.create(\n",
        "    input=words_n_base,\n",
        "    engine=\"text-similarity-davinci-001\")\n",
        "\n",
        "\n",
        "words_n_base_front = [\"Frontend Developer\",\"UI Implementation\",\"Frontend Architecture\",\"General Frontend Support\",\"Web Development\",\"App Development\"]\n",
        "resp_base_front = openai.Embedding.create(\n",
        "    input=words_n_base_front,\n",
        "    engine=\"text-similarity-davinci-001\")\n",
        "\n",
        "\n",
        "words_n_base_product = [\"Product Manager\",\"User Research\",\"Market Research\",\"Technical Team Coordination\",\"Design Team Coordination\",\"Ideation\",\"Interviews\"]\n",
        "resp_base_product = openai.Embedding.create(\n",
        "    input=words_n_base_product,\n",
        "    engine=\"text-similarity-davinci-001\")\n",
        "\n",
        "\n",
        "words_n_all = []\n",
        "words_n_all.append(words_n_base)\n",
        "words_n_all.append(words_n_base_front)\n",
        "words_n_all.append(words_n_base_front)"
      ],
      "metadata": {
        "id": "uJQ1P7fsTyX4"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words_embed = []\n",
        "for i in range(len( resp['data'])):\n",
        "  words_embed.append(resp['data'][i]['embedding'])\n",
        "\n",
        "\n",
        "words_embed_base = []\n",
        "for i in range(len( resp_base['data'])):\n",
        "  words_embed_base.append(resp_base['data'][i]['embedding'])\n",
        "\n",
        "\n",
        "words_embed_base_front = []\n",
        "for i in range(len( resp_base_front['data'])):\n",
        "  words_embed_base_front.append(resp_base_front['data'][i]['embedding'])\n",
        "\n",
        "\n",
        "words_embed_base_product = []\n",
        "for i in range(len( resp_base_product['data'])):\n",
        "  words_embed_base_product.append(resp_base_product['data'][i]['embedding'])\n",
        "\n",
        "\n",
        "words_base_all = []\n",
        "words_base_all.append(words_embed_base)\n",
        "words_base_all.append(words_embed_base_front)\n",
        "words_base_all.append(words_embed_base_product)\n",
        "\n",
        "# print(words_base_all[1])\n",
        "# print(words_embed_base_front)"
      ],
      "metadata": {
        "id": "I5S-imSkUGyI"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "k = 10 # k best embeddings\n",
        "emb_mat = np.stack(words_embed)\n",
        "# print(emb_mat)\n",
        "\n",
        "emb_mat_base_all = []\n",
        "for i in range(len(words_base_all)):\n",
        "  emb_mat_base = np.stack(words_base_all[i])\n",
        "  \n",
        "  emb_mat_base_all.append(emb_mat_base)\n",
        "\n",
        "\n",
        "emb_mat_base = np.stack(words_embed_base)\n",
        "# print(emb_mat_base)\n",
        "\n",
        "\n",
        "emb_mat_base_front = np.stack(words_embed_base_front)\n",
        "# print(emb_mat_base_front)\n",
        "\n",
        "emb_mat_base_product = np.stack(words_embed_base_product)\n",
        "# print(emb_mat_base_product)\n"
      ],
      "metadata": {
        "id": "f9YefpiYND3n"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chooseWord = 3\n",
        "scores = np.dot(emb_mat_base,emb_mat.T)\n",
        "# scores = np.dot(emb_mat,emb_mat_base.T)\n",
        "print(scores)\n",
        "\n",
        "\n",
        "scores_base_all = []\n",
        "for i in range(len(words_base_all)):\n",
        "  scores_base = np.dot(emb_mat_base_all[i],emb_mat.T)\n",
        "  \n",
        "  scores_base_all.append(scores_base)\n",
        "\n",
        "\n",
        "scores_front = np.dot(emb_mat_base_front,emb_mat.T)\n",
        "\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(scores_front)\n",
        "\n",
        "\n",
        "scores_product = np.dot(emb_mat_base_product,emb_mat.T)\n",
        "\n",
        "\n",
        "print()\n",
        "print()\n",
        "\n",
        "print(scores_product)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yV172DOxNPUC",
        "outputId": "ec888645-c8bc-440b-803a-b1fbe3dd5c27"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.76578132 0.83401948 0.83865283]\n",
            " [0.78244649 0.81227447 0.80754811]\n",
            " [0.75696196 0.76545913 0.77118749]\n",
            " [0.79935827 0.78208007 0.78191594]\n",
            " [0.78141215 0.79285492 0.79375412]\n",
            " [0.78391109 0.83769334 0.83037538]\n",
            " [0.7210471  0.70193232 0.69224291]\n",
            " [0.78238383 0.7842773  0.78352532]\n",
            " [0.77036025 0.8122506  0.80716802]]\n",
            "\n",
            "\n",
            "[[0.8086257  0.76054106 0.76337418]\n",
            " [0.80944652 0.82348674 0.81145058]\n",
            " [0.81718861 0.77738603 0.78413234]\n",
            " [0.78341721 0.75856752 0.75249162]\n",
            " [0.82747576 0.77753399 0.77455082]\n",
            " [0.81228519 0.78980126 0.78717936]]\n",
            "\n",
            "\n",
            "[[0.76814859 0.76313447 0.75750518]\n",
            " [0.7856003  0.79001378 0.7698769 ]\n",
            " [0.76696649 0.77229188 0.76144647]\n",
            " [0.7747524  0.751466   0.74593608]\n",
            " [0.76080362 0.75893328 0.75007299]\n",
            " [0.76844286 0.82414519 0.81413349]\n",
            " [0.77165414 0.77984377 0.77985902]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "maxima = list(map(max, scores))\n",
        "print(maxima)  # Output: [3, 6, 9]\n",
        "\n",
        "maxima_base_all = []\n",
        "for i in range(len(words_base_all)):\n",
        "  maxima_base = list(map(max, scores_base_all[i]))\n",
        "  \n",
        "  maxima_base_all.append(maxima_base)\n",
        "\n",
        "\n",
        "maxima_front = list(map(max, scores_front))\n",
        "print(maxima_front)  # Output: [3, 6, 9]\n",
        "\n",
        "maxima_product = list(map(max, scores_product))\n",
        "print(maxima_product)  # Output: [3, 6, 9]\n",
        "\n",
        "\n",
        "print(maxima_base_all)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvzUMQ7NVnd7",
        "outputId": "e0a89bf3-0893-4054-c8d4-31bd56f0c615"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.8386528297724409, 0.8122744723271862, 0.7711874892827058, 0.7993582653380178, 0.7937541152594048, 0.8376933389284876, 0.7210471043191763, 0.7842772957201889, 0.8122506044192864]\n",
            "[0.8086257043868713, 0.8234867397838965, 0.8171886081055226, 0.7834172130793375, 0.8274757599086624, 0.8122851896801885]\n",
            "[0.768148593397363, 0.7900137834096558, 0.7722918809946744, 0.7747523984526041, 0.7608036175541735, 0.8241451947115287, 0.7798590247500595]\n",
            "[[0.8386528297724409, 0.8122744723271862, 0.7711874892827058, 0.7993582653380178, 0.7937541152594048, 0.8376933389284876, 0.7210471043191763, 0.7842772957201889, 0.8122506044192864], [0.8086257043868713, 0.8234867397838965, 0.8171886081055226, 0.7834172130793375, 0.8274757599086624, 0.8122851896801885], [0.768148593397363, 0.7900137834096558, 0.7722918809946744, 0.7747523984526041, 0.7608036175541735, 0.8241451947115287, 0.7798590247500595]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "average_n = sum(maxima) / len(maxima)\n",
        "print(\"average Design:\",average_n)\n",
        "\n",
        "\n",
        "average_base_all = []\n",
        "for i in range(len(words_base_all)):\n",
        "  average_base = sum(maxima_base_all[i]) / len(maxima_base_all[i])\n",
        "  \n",
        "  average_base_all.append(average_base)\n",
        "\n",
        "\n",
        "average_n_front = sum(maxima_front) / len(maxima_front)\n",
        "print(\"average FrontEnd:\",average_n_front)\n",
        "\n",
        "average_n_product = sum(maxima_product) / len(maxima_product)\n",
        "print(\"average Product:\",average_n_product)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print(average_base_all)"
      ],
      "metadata": {
        "id": "FVZQQdDYnC7R",
        "outputId": "d09a7c56-848d-4e97-da53-d543dccc6117",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average Design: 0.796721723929655\n",
            "average FrontEnd: 0.8120798691574133\n",
            "average Product: 0.7814306418957228\n",
            "[0.796721723929655, 0.8120798691574133, 0.7814306418957228]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# python find the position of the bigger number on the array called average_base_all\n",
        "pos_knowGr = average_base_all.index(max(average_base_all))\n",
        "print(\"The position of the bigger number is:\", pos_knowGr)\n",
        "scores = scores_base_all[pos_knowGr]\n",
        "words_n_base = words_n_all[pos_knowGr]\n",
        "\n",
        "\n",
        "\n",
        "# if (average_n>average_n_front and average_n>average_n_product):\n",
        "#   # Do nothing\n",
        "#   a = 1\n",
        "\n",
        "# if (average_n_front>average_n and average_n_front>average_n_product):\n",
        "#   scores = scores_front\n",
        "#   words_n_base = words_n_base_front\n",
        "\n",
        "# if (average_n_product>average_n and average_n_product>average_n_front):\n",
        "#   scores = scores_product\n",
        "#   words_n_base = words_n_base_product"
      ],
      "metadata": {
        "id": "GjSSB4PespX2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ee04deb-9ced-4be8-d866-e16d0a50855c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The position of the bigger number is: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_pos = scores.argmax(axis=1)\n",
        "\n",
        "print(max_pos)\n",
        "\n",
        "words_np = np.array(words_n)\n",
        "print(max_pos)  \n",
        "print(scores)\n",
        "print(\"\")\n",
        "numberClose = 2\n",
        "threshold = 0.6\n",
        "for i in range(len(max_pos)):\n",
        "  max_elements_position = np.argpartition(scores[i], -numberClose)[-numberClose:]\n",
        "  print(max_elements_position)\n",
        "  # print(\"Correlation = \",scores[i][max_elements_position])\n",
        "\n",
        "  # scores_max_bigger_threshold = [number for number in scores[i][max_elements_position] if number > threshold]\n",
        "\n",
        "  # scores_max_bigger_threshold = []\n",
        "  # for number in scores[i][max_elements_position]:\n",
        "  #   if number > threshold:\n",
        "  #     scores_max_bigger_threshold.append(number)\n",
        "\n",
        "  scores_max_bigger_threshold = []\n",
        "  position_bigger_threshold = []\n",
        "  for pos in max_elements_position:\n",
        "    number = scores[i][pos]\n",
        "    if number > threshold:\n",
        "      scores_max_bigger_threshold.append(number)\n",
        "      position_bigger_threshold.append(pos)\n",
        "\n",
        "  # print(\"Correlation = \" , scores_max_bigger_threshold)\n",
        "\n",
        "\n",
        "  print(\"Base Knowledge Graph Name = \",words_n_base[i])\n",
        "  print(\"Best word to connect = \",words_np[position_bigger_threshold])\n",
        "  print(\"Correlation = \",scores[i][position_bigger_threshold])\n",
        "\n",
        "  # print(\"Base Knowledge Graph Name = \",words_n_base[i])\n",
        "  # print(\"Best word to connect = \",words_np[max_elements_position])\n",
        "  # print(\"Correlation = \",scores[i][max_elements_position])\n",
        "\n",
        "\n",
        "  # print(\"Base Knowledge Graph Name = \",words_n_base[i])\n",
        "  # print(\"Best word to connect = \",words_n[max_pos[i]])\n",
        "  # print(\"Correlation = \",scores[i][max_pos[i]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HB0y0EFOV_m8",
        "outputId": "461db828-8576-450c-8958-6abc53a0d40b"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0 1 0 0 0 0]\n",
            "[0 1 0 0 0 0]\n",
            "[[0.8086257  0.76054106 0.76337418]\n",
            " [0.80944652 0.82348674 0.81145058]\n",
            " [0.81718861 0.77738603 0.78413234]\n",
            " [0.78341721 0.75856752 0.75249162]\n",
            " [0.82747576 0.77753399 0.77455082]\n",
            " [0.81228519 0.78980126 0.78717936]]\n",
            "\n",
            "[2 0]\n",
            "Base Knowledge Graph Name =  Frontend Developer\n",
            "Best word to connect =  ['angular' '\\n\\nnode.js']\n",
            "Correlation =  [0.76337418 0.8086257 ]\n",
            "[2 1]\n",
            "Base Knowledge Graph Name =  UI Implementation\n",
            "Best word to connect =  ['angular' 'react']\n",
            "Correlation =  [0.81145058 0.82348674]\n",
            "[2 0]\n",
            "Base Knowledge Graph Name =  Frontend Architecture\n",
            "Best word to connect =  ['angular' '\\n\\nnode.js']\n",
            "Correlation =  [0.78413234 0.81718861]\n",
            "[1 0]\n",
            "Base Knowledge Graph Name =  General Frontend Support\n",
            "Best word to connect =  ['react' '\\n\\nnode.js']\n",
            "Correlation =  [0.75856752 0.78341721]\n",
            "[1 0]\n",
            "Base Knowledge Graph Name =  Web Development\n",
            "Best word to connect =  ['react' '\\n\\nnode.js']\n",
            "Correlation =  [0.77753399 0.82747576]\n",
            "[1 0]\n",
            "Base Knowledge Graph Name =  App Development\n",
            "Best word to connect =  ['react' '\\n\\nnode.js']\n",
            "Correlation =  [0.78980126 0.81228519]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h3>Clustering</h3>"
      ],
      "metadata": {
        "id": "jI9wUPHSVzHn"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ntc2x0i2xydm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}